{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvgUl5C2b9Uz1szKMo+n7g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dewoller/uofl_seminars/blob/main/lm_4_penguinsA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "xRBWKKeq5w9W",
        "outputId": "dbd997a0-4dd0-42b8-f543-de2d0a73d8b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing packages into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘shape’, ‘future.apply’, ‘numDeriv’, ‘progressr’, ‘SQUAREM’, ‘Rcpp’, ‘diagram’, ‘lava’, ‘listenv’, ‘parallelly’, ‘prodlim’, ‘future’, ‘warp’, ‘iterators’, ‘lhs’, ‘DiceDesign’, ‘patchwork’, ‘globals’, ‘clock’, ‘gower’, ‘ipred’, ‘timeDate’, ‘furrr’, ‘slider’, ‘foreach’, ‘GPfit’, ‘modelenv’, ‘dials’, ‘hardhat’, ‘infer’, ‘modeldata’, ‘parsnip’, ‘recipes’, ‘rsample’, ‘tune’, ‘workflows’, ‘workflowsets’, ‘yardstick’\n",
            "\n",
            "\n",
            "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 1.1.1 ──\n",
            "\n",
            "\u001b[32m✔\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.5     \u001b[32m✔\u001b[39m \u001b[34mrecipes     \u001b[39m 1.0.9\n",
            "\u001b[32m✔\u001b[39m \u001b[34mdials       \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mrsample     \u001b[39m 1.2.0\n",
            "\u001b[32m✔\u001b[39m \u001b[34mdplyr       \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mtibble      \u001b[39m 3.2.1\n",
            "\u001b[32m✔\u001b[39m \u001b[34mggplot2     \u001b[39m 3.4.4     \u001b[32m✔\u001b[39m \u001b[34mtidyr       \u001b[39m 1.3.0\n",
            "\u001b[32m✔\u001b[39m \u001b[34minfer       \u001b[39m 1.0.5     \u001b[32m✔\u001b[39m \u001b[34mtune        \u001b[39m 1.1.2\n",
            "\u001b[32m✔\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.3.0     \u001b[32m✔\u001b[39m \u001b[34mworkflows   \u001b[39m 1.1.3\n",
            "\u001b[32m✔\u001b[39m \u001b[34mparsnip     \u001b[39m 1.1.1     \u001b[32m✔\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.0.1\n",
            "\u001b[32m✔\u001b[39m \u001b[34mpurrr       \u001b[39m 1.0.2     \u001b[32m✔\u001b[39m \u001b[34myardstick   \u001b[39m 1.3.0\n",
            "\n",
            "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
            "\u001b[31m✖\u001b[39m \u001b[34mpurrr\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mscales\u001b[39m::discard()\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m  masks \u001b[34mstats\u001b[39m::filter()\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m     masks \u001b[34mstats\u001b[39m::lag()\n",
            "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m  masks \u001b[34mstats\u001b[39m::step()\n",
            "\u001b[34m•\u001b[39m Learn how to get started at \u001b[32mhttps://www.tidymodels.org/start/\u001b[39m\n",
            "\n",
            "\n",
            "Attaching package: ‘palmerpenguins’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:modeldata’:\n",
            "\n",
            "    penguins\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           Truth\n",
              "Prediction  Adelie Chinstrap Gentoo\n",
              "  Adelie        37         0      0\n",
              "  Chinstrap      0        21      0\n",
              "  Gentoo         0         0     26"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Install packages if not already installed\n",
        "#install.packages(c(\"tidymodels\", \"palmerpenguins\"))\n",
        "\n",
        "# Load the necessary libraries\n",
        "library(tidymodels) # Loads the tidymodels framework for modeling and machine learning\n",
        "library(palmerpenguins) # Loads the Palmer Penguins dataset\n",
        "\n",
        "# Step 2: Prepare the Data\n",
        "# Load and preprocess the data. We'll remove missing values and split the data into training and testing sets.\n",
        "\n",
        "# Load the data and remove missing values\n",
        "data(\"penguins\") # Loads the penguins dataset\n",
        "penguins_clean <- drop_na(penguins) # Removes rows with any missing values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "set.seed(123) # Ensures reproducible results when splitting the data\n",
        "split <- initial_split(penguins_clean, prop = 0.75) # Splits the data, with 75% for training\n",
        "train_data <- training(split) # Extracts the training set\n",
        "test_data <- testing(split) # Extracts the testing set\n",
        "\n",
        "# Step 3: Create a Recipe\n",
        "# A recipe specifies the preprocessing steps. For this example, we'll just deal with missing data, but typically, you could also specify steps for normalization, factor encoding, etc.\n",
        "\n",
        "recipe <- recipe(species ~ ., data = train_data) %>%\n",
        "  step_dummy(all_nominal(), -all_outcomes()) %>% # Converts all nominal variables to dummy variables, except the outcome variable\n",
        "  step_zv(all_predictors()) %>%\n",
        "  step_normalize(all_numeric(), -all_outcomes()) # Normalizes all numeric predictors, excluding the outcome variable\n",
        "\n",
        "# Step 4: Specify the Model\n",
        "# For a multinomial classification problem, we can use a model like multinomial logistic regression. The tidymodels framework allows for easy specification of such models.\n",
        "\n",
        "model_spec <- multinom_reg() %>%\n",
        "  set_engine(\"nnet\") %>%\n",
        "  set_mode(\"classification\") # Specifies a multinomial logistic regression model using the 'nnet' engine for classification\n",
        "\n",
        "# Step 5: Bundle Preprocessing and Model in a Workflow\n",
        "# A workflow in tidymodels bundles together your preprocessing steps and model.\n",
        "\n",
        "workflow <- workflow() %>%\n",
        "  add_recipe(recipe) %>%\n",
        "  add_model(model_spec) # Combines the preprocessing recipe and model specification into a workflow\n",
        "\n",
        "# Step 6: Fit the Model\n",
        "# Fit the model to the training data using the workflow.\n",
        "\n",
        "fitted_model <- workflow %>%\n",
        "  fit(data = train_data) # Fits the specified model to the training data\n",
        "\n",
        "# Step 7: Evaluate the Model\n",
        "# Predict on the test set and evaluate the model's performance.\n",
        "\n",
        "results <- fitted_model %>%\n",
        "  predict(new_data = test_data) %>%\n",
        "  bind_cols(test_data) %>%\n",
        "  metrics(truth = species, estimate = .pred_class) %>%\n",
        "  select(.metric, .estimate) # Predicts species on the test data, binds predictions to true values, and calculates metrics\n",
        "\n",
        "# View the results\n",
        "# For a more detailed performance evaluation, confusion matrices or other classification metrics.\n",
        "\n",
        "conf_mat <- fitted_model %>%\n",
        "  predict(new_data = test_data) %>%\n",
        "  bind_cols(test_data) %>%\n",
        "  conf_mat(truth = species, estimate = .pred_class) # Generates a confusion matrix from predictions\n",
        "\n",
        "conf_mat\n"
      ]
    }
  ]
}